{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending inferred blks together..\n",
    "\n",
    "<img src=\"Blending.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import blending function from Function.py...\n",
    "\n",
    "Get the path of the inferred not yet stitched samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of prepped upenn specimen:  120\n",
      "no. of specimen inferred: 118\n",
      "no. of specimen inferred not stitched: 105\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from Function import read_niigz, Blend, save_niigz\n",
    "\n",
    "# Define the root folder\n",
    "rootfolder = r\"W:/UPenn_Clinical\"\n",
    "inferred_dataset = \"results913\"\n",
    "\n",
    "# Initialize a list to store file paths for both AFM and EAM samples\n",
    "file_paths = []\n",
    "\n",
    "# Iterate over the directories in the root folder\n",
    "for folder in os.listdir(rootfolder):\n",
    "    full_folder_path = os.path.join(rootfolder, folder)\n",
    "\n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(full_folder_path):\n",
    "        # Determine if the folder name starts with \"OTLS\" or \"Oxford\"\n",
    "        if folder.startswith(\"OTLS\") or folder.startswith(\"Oxford\"):\n",
    "            # Check for AFM or EAM in the folder name\n",
    "            if \"AFM\" in folder or \"EAM\" in folder:\n",
    "                # Check for fused_corrected1.h5 in the subfolders\n",
    "                if \"nnunet\" in os.listdir(full_folder_path):\n",
    "                    file_paths.append(os.path.join(full_folder_path,\"nnunet\"))\n",
    "                for subfolder in os.listdir(full_folder_path):\n",
    "                    subfolder_path = os.path.join(full_folder_path, subfolder)\n",
    "                    if os.path.isdir(subfolder_path):\n",
    "                        # Check in subfolder for the file\n",
    "                        if \"nnunet\" in os.listdir(subfolder_path):\n",
    "                            file_paths.append(os.path.join(subfolder_path, \"nnunet\"))\n",
    "\n",
    "# Print the results\n",
    "print(\"no. of prepped upenn specimen: \", len(file_paths))\n",
    "\n",
    "inferred = [] \n",
    "inferred_not_stitched = []\n",
    "for nnunet in file_paths:\n",
    "    if inferred_dataset in os.listdir(nnunet):\n",
    "        inferred.append(nnunet)\n",
    "        stitched_folder = os.path.join(nnunet,inferred_dataset,\"stitched\")\n",
    "        if not os.path.exists(stitched_folder):\n",
    "            inferred_not_stitched.append(nnunet)\n",
    "        else:\n",
    "            if \"stitched_volume.nii.gz\" not in os.listdir(stitched_folder):\n",
    "                inferred_not_stitched.append(nnunet)\n",
    "print(\"no. of specimen inferred:\", len(inferred))\n",
    "print(\"no. of specimen inferred not stitched:\", len(inferred_not_stitched))\n",
    "results = [os.path.join(i, inferred_dataset) for i in inferred_not_stitched]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_inferred = []\n",
    "for nnunet in file_paths:\n",
    "    if inferred_dataset not in os.listdir(nnunet):\n",
    "        not_inferred.append(nnunet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [    \n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_1-17-23_AFM004_well_5/030322fused/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_3-21-23_EAM003_well_1/fused_033023/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_3-21-23_EAM004_well_3/fused_033023/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_3-21-23_EAM005_well_5/fused_042523/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_3-3-23_AFM015_well_1/fused_032923/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_4-28-23_AFM062_well_7/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_4-28-23_AFM064_well_9/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_4-5-23_AFM046_well_3/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_4-5-23_AFM051_well_9/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_4-6-23_AFM053_well_3/nnunet\"  ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_5-10-23_EAM051_well_1/nnunet\"  ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_5-10-23_EAM053_well_5/nnunet\" ,\n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_5-21-23_AFM083_well_8/nnunet\" #partly\n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_5-21-23_EAM059_well_5/nnunet\" #partly\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_5-4-23_EAM040_well_7/nnunet\" ,\n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_5-7-23_EAM046_well_5/nnunet\" \n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_5-9-23_EAM048_well_8/nnunet\" \n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_6-1-23_EAM067_well_1/nnunet\" \n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_6-14-23_EAM079_well_1/nnunet\" \n",
    "    # \"A:/UPenn_Clinical/OTLS4_NODO_6-15-23_EAM083_well_1/nnunet\" \n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_6-16-23_EAM084_well_1/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_6-16-23_EAM087_well_3/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_6-5-23_EAM063_well_9/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_6-6-23_EAM077_well_8/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_9-13-23_AFM029_well_4/nnunet\",\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_9-13-23_EAM009_well_5/nnunet\" ,\n",
    "    \"A:/UPenn_Clinical/OTLS4_NODO_9-13-23_EAM015_well_9/nnunet\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching: /media/W/UPenn_Clinical/OTLS4_NODO_6-9-23_AFM098_well_9/nnunet/results807_ep1500/stitched\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    output_dir = result + os.sep + \"stitched\"\n",
    "    print(f\"Stitching: {output_dir}\")\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    output_path = output_dir + os.sep + \"stitched_volume.nii.gz\"\n",
    "    if not os.path.exists(output_path):\n",
    "        stitched_volume = Blend(result, output_path, blocksize = 1024, overlap_percentage = 0.25)\n",
    "        # Save the stitched volume\n",
    "        save_niigz(stitched_volume, output_path)\n",
    "        print(f\"Stitched volume saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a list of results directory and blend.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching: W:\\UPenn_Clinical\\OTLS4_NODO_4-4-23_AFM045_well_1\\nnunet\\results913\\stitched\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     os\u001b[39m.\u001b[39mmkdir(output_dir)\n\u001b[0;32m     11\u001b[0m output_path \u001b[39m=\u001b[39m output_dir \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstitched_volume.nii.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m stitched_volume \u001b[39m=\u001b[39m Blend(result, output_path, blocksize \u001b[39m=\u001b[39;49m \u001b[39m1024\u001b[39;49m, overlap_percentage \u001b[39m=\u001b[39;49m \u001b[39m0.25\u001b[39;49m)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Save the stitched volume\u001b[39;00m\n\u001b[0;32m     15\u001b[0m save_niigz(stitched_volume, output_path)\n",
      "File \u001b[1;32mz:\\Sarah\\nnUNet_on_Upenn\\Function.py:186\u001b[0m, in \u001b[0;36mBlend\u001b[1;34m(savepath, output_path, blocksize, overlap_percentage)\u001b[0m\n\u001b[0;32m    183\u001b[0m block_files \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(savepath) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.nii.gz\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m    185\u001b[0m \u001b[39m# Extract the image shape from one of the blocks\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m example_block \u001b[39m=\u001b[39m read_niigz(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(savepath, block_files[\u001b[39m0\u001b[39;49m]))\n\u001b[0;32m    187\u001b[0m depth \u001b[39m=\u001b[39m example_block\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n\u001b[0;32m    189\u001b[0m \u001b[39m# Calculate the number of blocks in x and y directions\u001b[39;00m\n",
      "File \u001b[1;32mz:\\Sarah\\nnUNet_on_Upenn\\utils.py:50\u001b[0m, in \u001b[0;36mread_niigz\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_niigz\u001b[39m(file_path):\n\u001b[0;32m     49\u001b[0m     img \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39mload(file_path)\n\u001b[1;32m---> 50\u001b[0m     data \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mget_fdata() \n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Sarah\\Lib\\site-packages\\nibabel\\dataobj_images.py:374\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[1;34m(self, caching, dtype)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fdata_cache\n\u001b[0;32m    371\u001b[0m \u001b[39m# Always return requested data type\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39m# during scaling\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masanyarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataobj, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    375\u001b[0m \u001b[39mif\u001b[39;00m caching \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfill\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fdata_cache \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Sarah\\Lib\\site-packages\\nibabel\\arrayproxy.py:454\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    434\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[39m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scaled(dtype\u001b[39m=\u001b[39;49mdtype, slicer\u001b[39m=\u001b[39;49m())\n\u001b[0;32m    455\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m         arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\Sarah\\Lib\\site-packages\\nibabel\\arrayproxy.py:423\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[1;34m(self, dtype, slicer)\u001b[0m\n\u001b[0;32m    421\u001b[0m scaled \u001b[39m=\u001b[39m apply_read_scaling(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_unscaled(slicer\u001b[39m=\u001b[39mslicer), scl_slope, scl_inter)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 423\u001b[0m     scaled \u001b[39m=\u001b[39m scaled\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mpromote_types(scaled\u001b[39m.\u001b[39;49mdtype, dtype), copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    424\u001b[0m \u001b[39mreturn\u001b[39;00m scaled\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from Function import read_niigz, Blend, save_niigz\n",
    "\n",
    "result = r\"W:\\UPenn_Clinical\\OTLS4_NODO_4-4-23_AFM045_well_1\\nnunet\\results913\"\n",
    "output_dir = result + os.sep + \"stitched\"\n",
    "print(f\"Stitching: {output_dir}\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "output_path = output_dir + os.sep + \"stitched_volume.nii.gz\"\n",
    "stitched_volume = Blend(result, output_path, blocksize = 1024, overlap_percentage = 0.25)\n",
    "\n",
    "# Save the stitched volume\n",
    "save_niigz(stitched_volume, output_path)\n",
    "print(f\"Stitched volume saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blended niigz to avi file for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nifti_to_video(nifti_path, output_path):\n",
    "    \"\"\"\n",
    "    Function to convert 3D NIfTI image to video\n",
    "    \"\"\"\n",
    "\n",
    "    nifti_img = nib.load(nifti_path)\n",
    "    img_data = nifti_img.dataobj[:,:,:round(nifti_img.shape[2]/2)]\n",
    "    data = transform.downscale_local_mean(img_data, # comment this if don't want downsampling\n",
    "                                                (2, 2, 1))\n",
    "    data = data*255\n",
    "    data = data.astype(np.uint8)\n",
    "\n",
    "    height, width, depth = data.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')  # Use MJPG codec\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 40, (width, height))\n",
    "\n",
    "    for i in range(depth):\n",
    "        slice_img = data[:, :, i]\n",
    "        colored_img = cv2.cvtColor(slice_img, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(colored_img)\n",
    "\n",
    "    out.release()\n",
    "\n",
    "\n",
    "for savepath in savepaths: # Change directory\n",
    "    folder_path = savepath + os.sep + \"stitched\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".nii.gz\"):\n",
    "            nifti_path = os.path.join(folder_path, filename)\n",
    "            output_path = os.path.join(folder_path, filename.replace(\".nii.gz\", \".avi\"))\n",
    "            print(output_path)\n",
    "            nifti_to_video(nifti_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sarah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
